{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e963cae",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-24T05:54:18.530734Z",
     "iopub.status.busy": "2025-12-24T05:54:18.530382Z",
     "iopub.status.idle": "2025-12-24T05:54:37.941357Z",
     "shell.execute_reply": "2025-12-24T05:54:37.940363Z"
    },
    "papermill": {
     "duration": 19.415107,
     "end_time": "2025-12-24T05:54:37.942679",
     "exception": false,
     "start_time": "2025-12-24T05:54:18.527572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Experiment Configuration ---\n",
      "Model: ConvNeXt_Tiny\n",
      "Seed:  42\n",
      "Device: cuda\n",
      "Data Root: /kaggle/input\n",
      "Source CSV not found at /kaggle/input/chexpert-processed/chexpert_20k_balanced.csv. Please check the path.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pediatric Pneumonia Screening: Multi-Center Cross-Domain Evaluation\n",
    "Training & Evaluation Pipeline\n",
    "\n",
    "Description:\n",
    "    This script implements the training and validation loop for three architectures:\n",
    "    EfficientNet-B0, ConvNeXt-Tiny, and ViT-Base-16.\n",
    "    It supports cross-domain evaluation on external datasets.\n",
    "\n",
    "Note for Reviewers:\n",
    "    - Paths are configured for the Kaggle environment but can be adapted for local use.\n",
    "    - Change MODEL_ARCHITECTURE and RANDOM_SEED in the 'Config' class to reproduce specific runs.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===================================================================\n",
    "# 1. Reproducibility & Configuration\n",
    "# ===================================================================\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    Sets seeds for all random number generators to ensure reproducibility.\n",
    "    Crucial for the stability analysis reported in the paper.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # Deterministic algorithms ensure that results are identical given the same seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class Config:\n",
    "    # --- A. Experiment Settings (Modify these to reproduce different runs) ---\n",
    "    # Options: \"EfficientNet_B0\", \"ConvNeXt_Tiny\", \"ViT_Base_16\"\n",
    "    MODEL_ARCHITECTURE = \"ConvNeXt_Tiny\" \n",
    "    \n",
    "    # Seeds used in the study: [42, 378, 1024, 2025, 4096]\n",
    "    RANDOM_SEED = 42\n",
    "    \n",
    "    # --- B. Hyperparameters ---\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    N_CPU = os.cpu_count()\n",
    "    EPOCHS = 15\n",
    "    BATCH_SIZE = 32\n",
    "    IMG_SIZE = 224\n",
    "    USE_LABEL_SMOOTHING = True\n",
    "    LABEL_SMOOTHING_FACTOR = 0.1\n",
    "    USE_TTA = True  # Test-Time Augmentation\n",
    "\n",
    "    # --- C. Path Configuration (Auto-detects Environment) ---\n",
    "    if os.path.exists('/kaggle/input'):\n",
    "        # Kaggle Environment\n",
    "        DATA_ROOT = '/kaggle/input'\n",
    "        OUTPUT_DIR = './'\n",
    "    else:\n",
    "        # Local Environment (Reviewer: Change this path to your data directory)\n",
    "        DATA_ROOT = './data'\n",
    "        OUTPUT_DIR = './weights'\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Dataset Paths (Relative to DATA_ROOT)\n",
    "    # Note: These paths assume the directory structure described in README.md\n",
    "    # You may need to adjust the CSV filename based on your data preparation step.\n",
    "    SOURCE_CSV_PATH = os.path.join(DATA_ROOT, 'chexpert-processed/chexpert_20k_balanced.csv') \n",
    "    EXTERNAL_TEST_DIR = os.path.join(DATA_ROOT, 'chest-xray-pneumonia/chest_xray/test')\n",
    "    \n",
    "    # --- D. Model Specifics ---\n",
    "    MODEL_ID = f\"{MODEL_ARCHITECTURE}_Seed{RANDOM_SEED}\"\n",
    "    \n",
    "    # Learning rates tailored for stability\n",
    "    LEARNING_RATES = {\n",
    "        \"EfficientNet_B0\": 1e-4,\n",
    "        \"ConvNeXt_Tiny\": 1e-4,\n",
    "        \"ViT_Base_16\": 3e-5\n",
    "    }\n",
    "    LEARNING_RATE = LEARNING_RATES[MODEL_ARCHITECTURE]\n",
    "\n",
    "# Initialize Config & Seed\n",
    "config = Config()\n",
    "seed_everything(config.RANDOM_SEED)\n",
    "\n",
    "print(f\"--- Experiment Configuration ---\")\n",
    "print(f\"Model: {config.MODEL_ARCHITECTURE}\")\n",
    "print(f\"Seed:  {config.RANDOM_SEED}\")\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "print(f\"Data Root: {config.DATA_ROOT}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. Data Loading\n",
    "# ===================================================================\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Assumes the CSV has 'Path' and 'label' columns\n",
    "        # Path adjustment for Kaggle/Local compatibility might be needed here\n",
    "        img_path = self.df.iloc[idx]['Path']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, torch.tensor(label, dtype=torch.long)\n",
    "        except Exception as e:\n",
    "            # Robustness: skip corrupted images during training\n",
    "            return None \n",
    "\n",
    "def collate_fn_robust(batch):\n",
    "    \"\"\"Filters out None samples (corrupted images) from the batch.\"\"\"\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Transforms (ImageNet normalization)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9), # Strong augmentation for generalization\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.85, 1.15)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ===================================================================\n",
    "# 3. Model Initialization\n",
    "# ===================================================================\n",
    "\n",
    "def get_model(architecture, num_classes=2):\n",
    "    \"\"\"\n",
    "    Factory function to initialize models with ImageNet weights\n",
    "    and modify the classification head.\n",
    "    \"\"\"\n",
    "    if architecture == \"EfficientNet_B0\":\n",
    "        model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "    elif architecture == \"ConvNeXt_Tiny\":\n",
    "        model = models.convnext_tiny(weights='IMAGENET1K_V1')\n",
    "        in_features = model.classifier[2].in_features\n",
    "        model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "    elif architecture == \"ViT_Base_16\":\n",
    "        model = models.vit_b_16(weights='IMAGENET1K_V1')\n",
    "        in_features = model.heads.head.in_features\n",
    "        model.heads.head = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {architecture}\")\n",
    "        \n",
    "    return model\n",
    "\n",
    "# ===================================================================\n",
    "# 4. Training & Evaluation Engine\n",
    "# ===================================================================\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress = tqdm(loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for images, labels in progress:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        progress.set_postfix(loss=loss.item())\n",
    "        \n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device, desc=\"Evaluating\", use_tta=False):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=desc, leave=False):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            if use_tta:\n",
    "                # Test-Time Augmentation: Average of Original + Horizontal Flip\n",
    "                out_1 = model(images)\n",
    "                out_2 = model(torch.flip(images, dims=[3]))\n",
    "                outputs = (torch.softmax(out_1, dim=1) + torch.softmax(out_2, dim=1)) / 2\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    report = classification_report(all_labels, all_preds, target_names=['Normal', 'Pneumonia'], digits=4)\n",
    "    return f1, report\n",
    "\n",
    "# ===================================================================\n",
    "# 5. Main Execution Loop\n",
    "# ===================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Load Data ---\n",
    "    if os.path.exists(config.SOURCE_CSV_PATH):\n",
    "        print(\"Loading Source Data...\")\n",
    "        full_df = pd.read_csv(config.SOURCE_CSV_PATH)\n",
    "        # Stratified split based on Seed\n",
    "        train_df, val_df = train_test_split(\n",
    "            full_df, test_size=0.2, \n",
    "            random_state=config.RANDOM_SEED, \n",
    "            stratify=full_df['label']\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            CustomDataset(train_df, transform=train_transforms),\n",
    "            batch_size=config.BATCH_SIZE, shuffle=True, \n",
    "            num_workers=config.N_CPU, collate_fn=collate_fn_robust\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            CustomDataset(val_df, transform=eval_transforms),\n",
    "            batch_size=config.BATCH_SIZE, shuffle=False, \n",
    "            num_workers=config.N_CPU, collate_fn=collate_fn_robust\n",
    "        )\n",
    "        \n",
    "        # --- Setup Model ---\n",
    "        model = get_model(config.MODEL_ARCHITECTURE).to(config.DEVICE)\n",
    "        \n",
    "        # Loss & Optimizer\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=config.LABEL_SMOOTHING_FACTOR)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.EPOCHS, eta_min=1e-7)\n",
    "        \n",
    "        # --- Training Loop ---\n",
    "        best_f1 = 0.0\n",
    "        print(\"\\nStarting Training...\")\n",
    "        \n",
    "        for epoch in range(1, config.EPOCHS + 1):\n",
    "            avg_loss = train_one_epoch(model, train_loader, criterion, optimizer, config.DEVICE)\n",
    "            val_f1, _ = evaluate(model, val_loader, config.DEVICE, desc=\"Validating\")\n",
    "            scheduler.step()\n",
    "            \n",
    "            print(f\"Epoch {epoch}/{config.EPOCHS} | Train Loss: {avg_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
    "            \n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1\n",
    "                save_path = os.path.join(config.OUTPUT_DIR, f\"{config.MODEL_ID}_best.pth\")\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                print(f\"--> Best model saved to {save_path}\")\n",
    "        \n",
    "        print(f\"\\nTraining Complete. Best Validation F1: {best_f1:.4f}\")\n",
    "\n",
    "        # --- External Evaluation (Example: Kaggle Pediatric) ---\n",
    "        if os.path.exists(config.EXTERNAL_TEST_DIR):\n",
    "            print(\"\\nRunning External Evaluation...\")\n",
    "            # Load best weights\n",
    "            model.load_state_dict(torch.load(save_path))\n",
    "            \n",
    "            test_dataset = datasets.ImageFolder(config.EXTERNAL_TEST_DIR, transform=eval_transforms)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, num_workers=config.N_CPU)\n",
    "            \n",
    "            ext_f1, ext_report = evaluate(model, test_loader, config.DEVICE, desc=\"Testing\", use_tta=config.USE_TTA)\n",
    "            print(f\"External Test F1 (TTA={config.USE_TTA}): {ext_f1:.4f}\")\n",
    "            print(ext_report)\n",
    "        else:\n",
    "            print(f\"\\nExternal test directory not found at {config.EXTERNAL_TEST_DIR}. Skipping external evaluation.\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"Source CSV not found at {config.SOURCE_CSV_PATH}. Please check the path.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1302315,
     "sourceId": 2169393,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8358875,
     "sourceId": 13190147,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.820446,
   "end_time": "2025-12-24T05:54:40.902571",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-24T05:54:13.082125",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
