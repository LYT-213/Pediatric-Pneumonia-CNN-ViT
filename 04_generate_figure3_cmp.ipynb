{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818fee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Figure 3 Generation: Direct Comparison of Attention Mechanisms (CNN vs ViT)\n",
    "\n",
    "Description:\n",
    "    This script generates a side-by-side comparison illustrating the \"Stability Gap\".\n",
    "    It visualizes the attention maps of ConvNeXt (Localized) and ViT (Diffuse)\n",
    "    on the same input image.\n",
    "    \n",
    "    Output: A single row figure with 3 panels: (A) Input, (B) ConvNeXt, (C) ViT.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Dependency Check ---\n",
    "try:\n",
    "    from pytorch_grad_cam import GradCAM, ScoreCAM \n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "except ImportError:\n",
    "    raise ImportError(\"Missing grad-cam. Please run: pip install -r requirements.txt\")\n",
    "\n",
    "# ===================================================================\n",
    "# 1. Configuration\n",
    "# ===================================================================\n",
    "\n",
    "class Config:\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Path Setup (Auto-detect)\n",
    "    if os.path.exists('/kaggle/input'):\n",
    "        DATA_ROOT = '/kaggle/input'\n",
    "        WEIGHTS_DIR = './' \n",
    "        # Using the same representative case\n",
    "        TEST_IMAGE_PATH = os.path.join(DATA_ROOT, 'chest-xray-pneumonia/chest_xray/test/PNEUMONIA/person80_bacteria_389.jpeg')\n",
    "    else:\n",
    "        DATA_ROOT = './data'\n",
    "        WEIGHTS_DIR = './weights'\n",
    "        TEST_IMAGE_PATH = './data/test/PNEUMONIA/case1.jpeg'\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# ===================================================================\n",
    "# 2. Helper Functions\n",
    "# ===================================================================\n",
    "\n",
    "def get_model(arch, weights_dir, device):\n",
    "    \"\"\"Loads a specific model architecture and its best weights.\"\"\"\n",
    "    if arch == \"ConvNeXt\":\n",
    "        model = models.convnext_tiny(weights=None)\n",
    "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, 2)\n",
    "        layer = [model.features[-1][-1]]\n",
    "    elif arch == \"ViT\":\n",
    "        model = models.vit_b_16(weights=None)\n",
    "        model.heads.head = nn.Linear(model.heads.head.in_features, 2)\n",
    "        layer = [model.encoder.layers[-1].ln_1]\n",
    "    \n",
    "    # Search for weights\n",
    "    search = os.path.join(weights_dir, f\"*{arch}*best.pth\")\n",
    "    files = glob.glob(search) + glob.glob(f\"{weights_dir}/**/*{arch}*best.pth\", recursive=True)\n",
    "    \n",
    "    if files:\n",
    "        state = torch.load(files[0], map_location=device)\n",
    "        state = {k.replace('module.', ''): v for k, v in state.items()}\n",
    "        model.load_state_dict(state, strict=False)\n",
    "        print(f\"Loaded {arch} weights from {os.path.basename(files[0])}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Weights for {arch} not found. Using random initialization.\")\n",
    "    \n",
    "    model.to(device).eval()\n",
    "    return model, layer\n",
    "\n",
    "def reshape_transform_vit(tensor):\n",
    "    \"\"\"Reshapes ViT embeddings for CAM.\"\"\"\n",
    "    result = tensor[:, 1:, :].reshape(tensor.size(0), 14, 14, tensor.size(2))\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result\n",
    "\n",
    "# ===================================================================\n",
    "# 3. Main Generation Loop\n",
    "# ===================================================================\n",
    "\n",
    "def generate_figure_3():\n",
    "    if not os.path.exists(config.TEST_IMAGE_PATH):\n",
    "        print(\"❌ Image not found. Please check configuration.\")\n",
    "        return\n",
    "\n",
    "    # Load & Preprocess Image\n",
    "    raw_img = Image.open(config.TEST_IMAGE_PATH).convert('RGB')\n",
    "    \n",
    "    # Transform for Model\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    input_tensor = transform(raw_img).unsqueeze(0).to(config.DEVICE)\n",
    "    \n",
    "    # Transform for Visualization\n",
    "    viz_img = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])(raw_img).numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    targets = [ClassifierOutputTarget(1)] # Target: Pneumonia\n",
    "\n",
    "    # 1. Generate ConvNeXt Map (Grad-CAM)\n",
    "    print(\"Generating ConvNeXt Map...\")\n",
    "    model_c, layer_c = get_model(\"ConvNeXt\", config.WEIGHTS_DIR, config.DEVICE)\n",
    "    with GradCAM(model=model_c, target_layers=layer_c) as cam:\n",
    "        map_c = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "    vis_c = show_cam_on_image(viz_img, map_c, use_rgb=True)\n",
    "\n",
    "    # 2. Generate ViT Map (Score-CAM)\n",
    "    print(\"Generating ViT Map (Score-CAM)...\")\n",
    "    model_v, layer_v = get_model(\"ViT\", config.WEIGHTS_DIR, config.DEVICE)\n",
    "    with ScoreCAM(model=model_v, target_layers=layer_v, reshape_transform=reshape_transform_vit) as cam:\n",
    "        # Batch size for memory safety\n",
    "        cam.batch_size = 16\n",
    "        map_v = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "    vis_v = show_cam_on_image(viz_img, map_v, use_rgb=True)\n",
    "\n",
    "    # 3. Plot Comparison\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    ax[0].imshow(raw_img)\n",
    "    ax[0].set_title(\"(A) Input CXR\", fontsize=14, y=-0.15)\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    ax[1].imshow(vis_c)\n",
    "    ax[1].set_title(\"(B) ConvNeXt (Focal Attention)\", fontsize=14, y=-0.15)\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    ax[2].imshow(vis_v)\n",
    "    ax[2].set_title(\"(C) ViT (Diffuse Attention)\", fontsize=14, y=-0.15)\n",
    "    ax[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = \"Figure_3_Comparison.tif\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "    print(f\"\\n✅ Figure 3 saved to {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_figure_3()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
