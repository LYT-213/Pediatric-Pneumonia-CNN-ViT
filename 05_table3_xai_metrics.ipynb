{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Table 3 Generation: Quantitative Explainability Metrics (Gini & Entropy)\n",
    "\n",
    "Description:\n",
    "    This script computes the Attention Concentration (Gini Coefficient) and \n",
    "    Dispersion (Entropy) metrics reported in Table 3 of the manuscript.\n",
    "    \n",
    "    It processes a stratified sample of images from external datasets to quantify \n",
    "    the \"Stability Gap\" between CNNs and Transformers.\n",
    "    \n",
    "    Methodology:\n",
    "    - ViT: Uses Score-CAM (computationally expensive but accurate for Global Attention).\n",
    "    - CNNs: Uses Grad-CAM (Standard approach).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Dependency Check ---\n",
    "try:\n",
    "    from pytorch_grad_cam import GradCAM, ScoreCAM\n",
    "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "except ImportError:\n",
    "    raise ImportError(\"Missing 'grad-cam'. Please install via requirements.txt\")\n",
    "\n",
    "# ===================================================================\n",
    "# 1. Configuration\n",
    "# ===================================================================\n",
    "\n",
    "class Config:\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    BATCH_SIZE = 1   # Keep 1 for XAI to avoid OOM with Score-CAM\n",
    "    SAMPLE_SIZE = 50 # Number of images per dataset to analyze (Stratified)\n",
    "    SEED = 42\n",
    "    \n",
    "    # --- Path Configuration (Auto-detect) ---\n",
    "    if os.path.exists('/kaggle/input'):\n",
    "        DATA_ROOT = '/kaggle/input'\n",
    "        WEIGHTS_DIR = './' \n",
    "        \n",
    "        # Adjust these to match your Kaggle dataset structure\n",
    "        KAGGLE_DIR = os.path.join(DATA_ROOT, 'chest-xray-pneumonia/chest_xray/test')\n",
    "        # VinDr Path (Example)\n",
    "        VINDR_ROOT = os.path.join(DATA_ROOT, 'vixdr/vindr-pcxr')\n",
    "    else:\n",
    "        DATA_ROOT = './data'\n",
    "        WEIGHTS_DIR = './weights'\n",
    "        KAGGLE_DIR = os.path.join(DATA_ROOT, 'kaggle/test')\n",
    "        VINDR_ROOT = os.path.join(DATA_ROOT, 'vindr')\n",
    "\n",
    "config = Config()\n",
    "print(f\"‚úÖ Environment Ready: {config.DEVICE}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. Metrics & Utilities\n",
    "# ===================================================================\n",
    "\n",
    "def calculate_gini(heatmap):\n",
    "    \"\"\"Calculates Gini Coefficient (0=Uniform/Diffuse, 1=Focused).\"\"\"\n",
    "    heatmap = heatmap.flatten() + 1e-7\n",
    "    heatmap = np.sort(heatmap)\n",
    "    n = len(heatmap)\n",
    "    index = np.arange(1, n + 1)\n",
    "    gini = (2 * np.sum(index * flat)) / (n * np.sum(flat)) - (n + 1) / n\n",
    "    # Re-implementation for numpy array\n",
    "    return (np.sum((2 * index - n - 1) * heatmap)) / (n * np.sum(heatmap))\n",
    "\n",
    "def calculate_entropy(heatmap):\n",
    "    \"\"\"Calculates Entropy (Higher = More Disordered/Diffuse).\"\"\"\n",
    "    heatmap = heatmap.flatten()\n",
    "    heatmap = heatmap / (np.sum(heatmap) + 1e-7)\n",
    "    heatmap = heatmap[heatmap > 0]\n",
    "    return -np.sum(heatmap * np.log2(heatmap))\n",
    "\n",
    "def read_image(path):\n",
    "    \"\"\"Universal image reader (DICOM/JPG/PNG) -> RGB 224x224.\"\"\"\n",
    "    try:\n",
    "        if path.endswith('.dicom') or not os.path.splitext(path)[1]:\n",
    "            dcm = pydicom.dcmread(path)\n",
    "            img = dcm.pixel_array\n",
    "            # Handle MONOCHROME1 (Invert)\n",
    "            if hasattr(dcm, \"PhotometricInterpretation\") and dcm.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "                img = np.max(img) - img\n",
    "            # Normalize\n",
    "            img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-6) * 255.0\n",
    "            img = img.astype(np.uint8)\n",
    "            if len(img.shape) == 2: img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        else:\n",
    "            img = np.array(Image.open(path).convert('RGB'))\n",
    "        \n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        return img\n",
    "    except: return None\n",
    "\n",
    "def reshape_transform_vit(tensor):\n",
    "    \"\"\"Reshapes ViT embeddings for CAM.\"\"\"\n",
    "    result = tensor[:, 1:, :].reshape(tensor.size(0), 14, 14, tensor.size(2))\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result\n",
    "\n",
    "# ===================================================================\n",
    "# 3. Model Loader\n",
    "# ===================================================================\n",
    "\n",
    "def get_model_and_cam(arch, weights_dir):\n",
    "    \"\"\"Initializes model and selects appropriate CAM method.\"\"\"\n",
    "    \n",
    "    # 1. Find Weights\n",
    "    search_path = os.path.join(weights_dir, f\"*{arch}*best.pth\")\n",
    "    # Recursive search to support Kaggle directory structure\n",
    "    files = glob.glob(search_path) + glob.glob(f\"/kaggle/input/**/*{arch}*best.pth\", recursive=True)\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"‚ö†Ô∏è No weights found for {arch}. Skipping.\")\n",
    "        return None, None\n",
    "\n",
    "    weights_path = files[0] # Pick the first match\n",
    "    \n",
    "    try:\n",
    "        # 2. Define Architecture\n",
    "        if 'efficientnet' in arch.lower():\n",
    "            model = models.efficientnet_b0(weights=None)\n",
    "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "            target_layers = [model.features[-1]]\n",
    "            cam_cls = GradCAM\n",
    "            \n",
    "        elif 'convnext' in arch.lower():\n",
    "            model = models.convnext_tiny(weights=None)\n",
    "            model.classifier[2] = nn.Linear(model.classifier[2].in_features, 2)\n",
    "            target_layers = [model.features[-1]]\n",
    "            cam_cls = GradCAM\n",
    "            \n",
    "        elif 'vit' in arch.lower():\n",
    "            model = models.vit_b_16(weights=None)\n",
    "            model.heads.head = nn.Linear(model.heads.head.in_features, 2)\n",
    "            target_layers = [model.encoder.layers[-1].ln_1]\n",
    "            cam_cls = ScoreCAM # Critical: GradCAM fails on ViT for this task\n",
    "            \n",
    "        # 3. Load State Dict\n",
    "        state = torch.load(weights_path, map_location=config.DEVICE)\n",
    "        state = {k.replace('module.', ''): v for k, v in state.items()}\n",
    "        model.load_state_dict(state, strict=False)\n",
    "        model.to(config.DEVICE).eval()\n",
    "        \n",
    "        # 4. Initialize CAM\n",
    "        if cam_cls == ScoreCAM:\n",
    "            cam = cam_cls(model=model, target_layers=target_layers, reshape_transform=reshape_transform_vit)\n",
    "            cam.batch_size = 16 # Batch processing for Score-CAM speedup\n",
    "        else:\n",
    "            cam = cam_cls(model=model, target_layers=target_layers)\n",
    "            \n",
    "        return model, cam\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {arch}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# ===================================================================\n",
    "# 4. Main Execution\n",
    "# ===================================================================\n",
    "\n",
    "def run_analysis():\n",
    "    # --- A. Prepare Samples (Stratified) ---\n",
    "    samples = {}\n",
    "    \n",
    "    # 1. Kaggle (Pneumonia class only for attention analysis)\n",
    "    if os.path.exists(config.KAGGLE_DIR):\n",
    "        files = glob.glob(os.path.join(config.KAGGLE_DIR, 'PNEUMONIA', '*'))\n",
    "        if files:\n",
    "            np.random.seed(config.SEED)\n",
    "            # Take random sample to ensure diversity\n",
    "            samples['Kaggle'] = np.random.choice(files, min(len(files), config.SAMPLE_SIZE), replace=False)\n",
    "    \n",
    "    # 2. VinDr (Scan for images if CSV logic is complex)\n",
    "    # Simplified logic: scan for files in VinDr test directory\n",
    "    vin_files = glob.glob(os.path.join(config.VINDR_ROOT, '**', '*.dicom'), recursive=True)\n",
    "    if not vin_files: # Try jpg/png\n",
    "        vin_files = glob.glob(os.path.join(config.VINDR_ROOT, '**', '*.jp*g'), recursive=True)\n",
    "        \n",
    "    if vin_files:\n",
    "        np.random.seed(config.SEED)\n",
    "        samples['VinDr'] = np.random.choice(vin_files, min(len(vin_files), config.SAMPLE_SIZE), replace=False)\n",
    "\n",
    "    print(f\"üìä Samples loaded: { {k:len(v) for k,v in samples.items()} }\")\n",
    "    \n",
    "    if not any(samples.values()):\n",
    "        print(\"‚ùå No images found. Check paths in Config.\")\n",
    "        return\n",
    "\n",
    "    # --- B. Processing Loop ---\n",
    "    architectures = ['EfficientNet_B0', 'ConvNeXt_Tiny', 'ViT_Base_16']\n",
    "    results = []\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    for arch in architectures:\n",
    "        print(f\"\\nü§ñ Analyzing {arch}...\")\n",
    "        model, cam = get_model_and_cam(arch, config.WEIGHTS_DIR)\n",
    "        if not model: continue\n",
    "        \n",
    "        for dataset_name, file_paths in samples.items():\n",
    "            ginis, entropies = [], []\n",
    "            \n",
    "            # Progress bar for images\n",
    "            for path in tqdm(file_paths, desc=f\"   {dataset_name}\", leave=False):\n",
    "                img = read_image(path)\n",
    "                if img is None: continue\n",
    "                \n",
    "                input_tensor = preprocess(Image.fromarray(img)).unsqueeze(0).to(config.DEVICE)\n",
    "                \n",
    "                try:\n",
    "                    # Generate Heatmap for 'Pneumonia' class (Target=1)\n",
    "                    heatmap = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(1)])[0, :]\n",
    "                    \n",
    "                    # Compute Metrics\n",
    "                    ginis.append(calculate_gini(heatmap))\n",
    "                    entropies.append(calculate_entropy(heatmap))\n",
    "                except Exception:\n",
    "                    continue # Skip failed images\n",
    "            \n",
    "            if ginis:\n",
    "                results.append({\n",
    "                    'Dataset': dataset_name,\n",
    "                    'Model': arch,\n",
    "                    'Gini Mean': np.mean(ginis),\n",
    "                    'Gini SD': np.std(ginis),\n",
    "                    'Entropy Me"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
