{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Figure 2 Generation: Comprehensive XAI Analysis (Grad-CAM, Score-CAM, LIME)\n",
    "\n",
    "Description:\n",
    "    This script generates the multi-panel visualization (Figure 2 in the manuscript).\n",
    "    It compares EfficientNet, ConvNeXt, and ViT on a representative test case, displaying:\n",
    "    1. Model Prediction & Confidence\n",
    "    2. Attention Heatmaps (Grad-CAM++ for CNNs, Score-CAM for ViT)\n",
    "    3. Quantitative Metrics (Gini Coefficient, Entropy)\n",
    "    4. LIME Explanations (Super-pixel perturbations)\n",
    "\n",
    "    Note: \n",
    "    - This process is computationally intensive due to LIME and Score-CAM.\n",
    "    - Ensure 'grad-cam' and 'lime' are installed via requirements.txt.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Dependency Check ---\n",
    "try:\n",
    "    from lime import lime_image\n",
    "    from pytorch_grad_cam import GradCAMPlusPlus, ScoreCAM\n",
    "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "except ImportError:\n",
    "    raise ImportError(\"Missing dependencies. Please run: pip install -r requirements.txt\")\n",
    "\n",
    "# ===================================================================\n",
    "# 1. Configuration & Paths\n",
    "# ===================================================================\n",
    "\n",
    "class Config:\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Path Setup (Auto-detect Environment)\n",
    "    if os.path.exists('/kaggle/input'):\n",
    "        DATA_ROOT = '/kaggle/input'\n",
    "        WEIGHTS_DIR = './' \n",
    "        # Specific case used in the paper (Adjust path if necessary)\n",
    "        TEST_IMAGE_PATH = os.path.join(DATA_ROOT, 'chest-xray-pneumonia/chest_xray/test/PNEUMONIA/person80_bacteria_389.jpeg')\n",
    "    else:\n",
    "        DATA_ROOT = './data'\n",
    "        WEIGHTS_DIR = './weights'\n",
    "        # Local placeholder path - Reviewer needs to update this\n",
    "        TEST_IMAGE_PATH = './data/test/PNEUMONIA/case1.jpeg'\n",
    "\n",
    "config = Config()\n",
    "print(f\"✅ Environment Ready: {config.DEVICE}\")\n",
    "\n",
    "# ===================================================================\n",
    "# 2. Quantitative Metrics (Gini & Entropy)\n",
    "# ===================================================================\n",
    "\n",
    "def calculate_gini(heatmap):\n",
    "    \"\"\"Calculates Gini Coefficient: Measure of attention sparsity (Higher = Focused).\"\"\"\n",
    "    if np.sum(heatmap) < 1e-9: return 0.0\n",
    "    flat = np.sort(heatmap.flatten())\n",
    "    n = len(flat)\n",
    "    index = np.arange(1, n + 1)\n",
    "    gini = (2 * np.sum(index * flat)) / (n * np.sum(flat)) - (n + 1) / n\n",
    "    return gini\n",
    "\n",
    "def calculate_entropy(heatmap):\n",
    "    \"\"\"Calculates Entropy: Measure of attention disorder (Lower = Focused).\"\"\"\n",
    "    if np.sum(heatmap) < 1e-9: return np.log(heatmap.size)\n",
    "    flat = heatmap.flatten() / (heatmap.sum() + 1e-9)\n",
    "    flat = flat[flat > 0]\n",
    "    return -np.sum(flat * np.log(flat))\n",
    "\n",
    "# ===================================================================\n",
    "# 3. Model Loading & XAI Utilities\n",
    "# ===================================================================\n",
    "\n",
    "def get_model_and_layers(architecture_name, weights_dir, device):\n",
    "    \"\"\"Initializes model and identifies target layers for CAM.\"\"\"\n",
    "    is_vit = False\n",
    "    target_layers = []\n",
    "    \n",
    "    # Search for weights file (Auto-find best model)\n",
    "    weight_path = None\n",
    "    search_pattern = os.path.join(weights_dir, f\"*{architecture_name}*best.pth\")\n",
    "    # Also search subdirectories\n",
    "    found_files = glob.glob(search_pattern) + glob.glob(f\"{weights_dir}/**/*{architecture_name}*best.pth\", recursive=True)\n",
    "    \n",
    "    if found_files:\n",
    "        weight_path = found_files[0]\n",
    "        print(f\"Loading {architecture_name} from: {os.path.basename(weight_path)}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Weights for {architecture_name} not found. Using random init (Sanity Check).\")\n",
    "\n",
    "    # Initialize Architecture\n",
    "    if architecture_name == \"EfficientNet_B0\":\n",
    "        model = models.efficientnet_b0(weights=None)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "        target_layers = [model.features[-1]]\n",
    "        \n",
    "    elif architecture_name == \"ConvNeXt_Tiny\":\n",
    "        model = models.convnext_tiny(weights=None)\n",
    "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, 2)\n",
    "        target_layers = [model.features[-1][-1]]\n",
    "        \n",
    "    elif architecture_name == \"ViT_Base_16\":\n",
    "        model = models.vit_b_16(weights=None)\n",
    "        model.heads.head = nn.Linear(model.heads.head.in_features, 2)\n",
    "        is_vit = True\n",
    "        # Target: Last LayerNorm of the Encoder (Crucial for ViT CAM)\n",
    "        target_layers = [model.encoder.layers[-1].ln_1]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown architecture\")\n",
    "\n",
    "    if weight_path:\n",
    "        try:\n",
    "            state = torch.load(weight_path, map_location=device)\n",
    "            state = {k.replace('module.', ''): v for k, v in state.items()}\n",
    "            model.load_state_dict(state, strict=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading weights: {e}\")\n",
    "    \n",
    "    model.to(device).eval()\n",
    "    return model, target_layers, is_vit\n",
    "\n",
    "def reshape_transform_vit(tensor):\n",
    "    \"\"\"Reshapes ViT patch embeddings to 2D grid for CAM compatibility.\"\"\"\n",
    "    result = tensor[:, 1:, :].reshape(tensor.size(0), 14, 14, tensor.size(2))\n",
    "    result = result.permute(0, 3, 1, 2)\n",
    "    return result\n",
    "\n",
    "def batch_predict_for_lime(model, numpy_images, device):\n",
    "    \"\"\"Prediction helper function for LIME.\"\"\"\n",
    "    model.eval()\n",
    "    # LIME passes numpy images, need to transform to Tensor\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    # Stack images into a batch\n",
    "    batch_tensor = torch.stack([preprocess(img) for img in numpy_images], dim=0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(batch_tensor)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# ===================================================================\n",
    "# 4. Main Generation Loop\n",
    "# ===================================================================\n",
    "\n",
    "def generate_figure_2():\n",
    "    if not os.path.exists(config.TEST_IMAGE_PATH):\n",
    "        print(f\"❌ Test image not found at {config.TEST_IMAGE_PATH}. Please check the path.\")\n",
    "        return\n",
    "\n",
    "    # Prepare Transforms\n",
    "    transform_viz = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "    transform_model = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    raw_pil = Image.open(config.TEST_IMAGE_PATH).convert('RGB')\n",
    "    input_tensor = transform_model(raw_pil).unsqueeze(0).to(config.DEVICE)\n",
    "    viz_img = transform_viz(raw_pil).numpy().transpose(1, 2, 0)\n",
    "\n",
    "    model_list = [\"EfficientNet_B0\", \"ConvNeXt_Tiny\", \"ViT_Base_16\"]\n",
    "    \n",
    "    # Initialize Plot\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "    \n",
    "    print(f\"\\nProcessing Image: {os.path.basename(config.TEST_IMAGE_PATH)}\")\n",
    "\n",
    "    for idx, arch in enumerate(model_list):\n",
    "        print(f\"\\n---> Analyzing {arch}...\")\n",
    "        model, layers, is_vit = get_model_and_layers(arch, config.WEIGHTS_DIR, config.DEVICE)\n",
    "        \n",
    "        # 1. Prediction\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_tensor)\n",
    "            probs = F.softmax(logits, dim=1)[0]\n",
    "            pred_class = torch.argmax(probs).item() # 1 = Pneumonia\n",
    "            conf = probs[pred_class].item()\n",
    "        \n",
    "        # 2. CAM (Attention)\n",
    "        # Use ScoreCAM for ViT (more accurate) and GradCAM++ for CNNs\n",
    "        cam_algo = ScoreCAM if is_vit else GradCAMPlusPlus\n",
    "        targets = [ClassifierOutputTarget(pred_class)]\n",
    "        \n",
    "        print(f\"     Generating {cam_algo.__name__}...\")\n",
    "        with cam_algo(model=model, target_layers=layers, \n",
    "                      reshape_transform=reshape_transform_vit if is_vit else None) as cam:\n",
    "            # Batch size limited to avoid OOM on ViT\n",
    "            if is_vit: cam.batch_size = 16\n",
    "            grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "            \n",
    "        cam_vis = show_cam_on_image(viz_img, grayscale_cam, use_rgb=True)\n",
    "        \n",
    "        # Calculate Metrics\n",
    "        gini = calculate_attention_concentration(grayscale_cam)\n",
    "        entropy = calculate_heatmap_entropy(grayscale_cam)\n",
    "\n",
    "        # 3. LIME (Explanation)\n",
    "        print(\"     Running LIME (This takes time)...\")\n",
    "        explainer = lime_image.LimeImageExplainer()\n",
    "        explanation = explainer.explain_instance(\n",
    "            (viz_img * 255).astype(np.uint8), \n",
    "            lambda x: batch_predict_for_lime(model, x, config.DEVICE),\n",
    "            top_labels=2, \n",
    "            hide_color=0, \n",
    "            num_samples=500, # Adjust samples for speed vs quality\n",
    "            random_seed=42\n",
    "        )\n",
    "        lime_vis, _ = explanation.get_image_and_mask(pred_class, positive_only=True, num_features=5, hide_rest=True)\n",
    "\n",
    "        # --- Plotting ---\n",
    "        # Col 1: Original + Label\n",
    "        axes[idx, 0].imshow(raw_pil)\n",
    "        axes[idx, 0].set_title(f\"{arch}\\nPred: {'Pneumonia' if pred_class==1 else 'Normal'} ({conf:.1%})\", fontsize=12, fontweight='bold', loc='left')\n",
    "        axes[idx, 0].axis('off')\n",
    "\n",
    "        # Col 2: CAM + Metrics\n",
    "        axes[idx, 1].imshow(cam_vis)\n",
    "        axes[idx, 1].set_title(f\"{'Score-CAM' if is_vit else 'Grad-CAM++'}\\nGini: {gini:.3f} | Ent: {entropy:.2f}\", fontsize=12)\n",
    "        axes[idx, 1].axis('off')\n",
    "\n",
    "        # Col 3: LIME\n",
    "        axes[idx, 2].imshow(lime_vis)\n",
    "        axes[idx, 2].set_title(\"LIME Super-pixels\", fontsize=12)\n",
    "        axes[idx, 2].axis('off')\n",
    "\n",
    "    # Save\n",
    "    save_path = \"Figure_2_XAI_Comparison.tif\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "    print(f\"\\n✅ Figure 2 saved to {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_figure_2()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
